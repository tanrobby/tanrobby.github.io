<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">
    <!-- <link rel="icon" href="../../favicon.ico"> -->

    <title>YNC Capstone</title>

    <!-- Bootstrap core CSS -->
    <link href="../../bootstrap-3.3.6-dist/css/bootstrap.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="../../jumbotron.css" rel="stylesheet">
  </head>

  <body>

    <nav class="navbar navbar-inverse navbar-fixed-top">
    </nav>

    <!-- Main jumbotron for a primary marketing message or call to action -->
    <div class="jumbotron">
      <div class="container"  style="font-size:16px">
        <h2>MCS Capstone Projects</h2>
        <p> Year 4 Students of
	  Yale-NUS College
	</p>
      </div>
    </div>


<div class="container" style="font-size:16px">



      <h3>Description:</h3>
      <p>
	The Yale-NUS curriculum culminates in an original capstone
	project which all students undertake with the guidance of
	Yale-NUS faculty and other subject matter experts. In the
	capstone program, students hone the disciplinary and general
	intellectual skills necessary to conceive, design and execute
	a year-long, self-directed project within their major. The
	program requires every student to engage with research in
	their discipline, to produce scholarship across appropriate
	formats, and to communicate their results to a variety of
	audiences. By completing their capstone work, students
	demonstrate independence, creativity and critical analysis. 
	</p>

	<p>
	Particularly, if
	you are interested in the areas of computer vision and machine
	learning/deep learning (applied to computer vision), please
	contact me as 
	your potential supervisor. For general information on the
	projects, please see the recommended topics below.
      </p>
      <br>
      Supervisor: <a href="http://tanrobby.github.io">Robby
	T. Tan</a> (robby.tan [att] yale-nus.edu.sg)
      <br>
      Supervisor guidelines and
      regulations: <a href="https://share.nus.edu.sg/ync/aa/students/Majors/Capstone%20guidelines%20regulations.pdf"
      target="_blank">PDF</a> 
      <br>


      <hr>
      <br>
      <h3>Recommended Topics:</h3>
      <p>
	Generally I'm interested in <u>applying deep learning techniques to
	computer vision problems</u>, particularly to the problems of bad
	weather, motion analysis, and human pose/action
	recognition. However, if you have 
	a specific plan in mind and you think my expertise can help, I
	am open for discussion.
      </p>
      <br>
      <ol class="list-group">
	
	<!------------------------------------------------>
	<li class="list-group-item list-group-item-info">
	  <b>Visibility in Bad Weather</b>
	  <br>
	  Visibility can be degraded significantly by atmospheric
	  particles such as fog or haze, rain streaks and raindrops.
	  This degraded visibility can cause many computer vision
	  algorithms to fail, since they usually assume a clear
	  day scene. In this topic, it would be interesting to see if deep
	  learning can help restore the visibility of degraded images
	  due to bad weather. A few researchers have shown that
	  Convolutional Neural Networks can be effective dealing with
	  some problems (such as haze or sparse raindrops), however
	  there are other bad weather conditions, where the problems
	  are not yet explored.
	  More information about this topic can be seen here:
	  <a href="../../focus_badweather.html" class="btn btn-default"
	  role="button">Visibility in  Bad Weather</a>
	</li>
	
	
	<!------------------------------------------------>
	<li class="list-group-item list-group-item-success">
	  <b>Motion Analysis</b>
	  <br>
	  Motion is one of the most basic cues of visual recognition. We can
	  identify the presence of an object immediately after we notice its
	  motion. Moreover, many high-level computer vision
	  algorithms, such as, action classification  or obstacle
	  detection, rely heavily on motion information. One type of
	  motion information is optical flow. While it has
	  been explored for many decades, most of the optical flow
	  algorithms are  not robust to some conditions where the
	  brightness 
	  constraint assumption is violated. Besides optical flow,
	  problems in dynamic texture analysis is interesting to
	  explore. Applications such as face expression or human
	  action recognition will greatly benefit from robust  motion
	  extraction. 
	  More information about this topic can be seen here:
	  <a href="../../focus_motion.html" class="btn btn-default"
	  role="button">Motion Analysis</a> 

	</li>
	
	<!------------------------------------------------>
	<li class="list-group-item list-group-item-warning">
	  <b>Human Pose/Action Recognition</b>
	  <br>
	  Humans are central to many computer applications, such as, 
	  human-computer interaction, video surveillance,
	  patients/elderly monitoring systems, store-goers behavior
	  analytical systems, 
	  etc.  Despite significant efforts to 
	  automate human action or pose recognition from video, the
	  problem is not yet solved. This is due to the complexity of human
	  actions and also due to the complexity of the
	  surrounding world. Occlusions, intractable body localization,
	  dressing styles,  cluttered background etc. are part of 
	  the complexity. Solving 
	  some problems in this area will be interesting from
	  both theoretical and practical perspectives. See the 
	  student projects below for some examples. 
	</li>

	
	<!------------------------------------------------>
	<!------------------------------------------------>
	
	
	</ol>

	</p>
      <br>
      <hr>
      <h3>Past Selected Student Projects:</h3>
      <br>

<ol class="list-group">

    <!------------------------------------------------>
  <li class="list-group-item">
    Elena Ursu, "Pose Estimation in Video", 2013: 
    [<a href="http://php-robbytan.rhcloud.com/others/2013_m_elena_ursu/index.html" target="_blank">project page</a>]
  </li>

  
    <!------------------------------------------------>
  <li class="list-group-item">
    Manuela Ichim, "Human Tracking and Orientation Estimation", 2013: 
    [<a href="http://php-robbytan.rhcloud.com/others/2013_m_manuela_ichim/index.htm" target="_blank">project page</a>]
  </li>
  

  
  
  <!------------------------------------------------>
  <li class="list-group-item">
    Jeffrey Resodikromo, "Markerless 3D pose estimation", 2012: 
    [<a href="http://php-robbytan.rhcloud.com/others/2012_m_jeffrey_resodikromo/index.html"
    target="_blank">project page</a>] 
  </li>
  
  <!------------------------------------------------>
  <li class="list-group-item">
    Michael Hobbel, "3D face reconstruction from a single image", 2012: 
    [<a href="http://php-robbytan.rhcloud.com/others/2012_e_michael_hobbel/index.html" target="_blank">project page</a>]
  </li>




    <!------------------------------------------------>
  <li class="list-group-item">
    Pascal Mettes, "Water Segmentation and Classification", 2013: 
    [<a href="http://php-robbytan.rhcloud.com/others/2013_m_pascal_mettes/index.html" target="_blank">project page</a>]
  </li>

  <!------------------------------------------------>
  <li class="list-group-item">
    Bob Boggemann, "Stereo Depth Estimation from Video Sequence", 2010: 
    [<a href="http://php-robbytan.rhcloud.com/others/2010_e_boggemann/index.htm" target="_blank">project page</a>]
  </li>


    <!------------------------------------------------>
  <li class="list-group-item">
    Charis Kontaxis, "Fluid Simulation", 2012: 
    [<a href="http://php-robbytan.rhcloud.com/others/2012_m_charis_kontaxis/index.html" target="_blank">project page</a>]
    
  </li>



  <!------------------------------------------------>
  <li class="list-group-item">
    Timothy Kol, "Analytical Sky Simulation", 2012: 
    [<a href="http://php-robbytan.rhcloud.com/others/2012_e_timothy_kol/index.html" target="_blank">project page</a>]
  </li>


    <!------------------------------------------------>
  <li class="list-group-item">
    Zhi Kang Shao, "Physically based rendering of mist and fog using MCML",  2013: 
    [<a href="http://php-robbytan.rhcloud.com/others/2013_e_zhikang_shao/index.htm" target="_blank">project page</a>]
  </li>

  
  <!------------------------------------------------>
  <!------------------------------------------------>

  
</ol>


</div>      
    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
    <script src="bootstrap-3.3.6-dist/js/bootstrap.min.js"></script>
  </body>
</html>
