<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">
    <!-- <link rel="icon" href="../../favicon.ico"> -->

    <title>YNC Machine Learning</title>
 
    <!-- Bootstrap core CSS -->
    <link href="../../bootstrap-3.3.6-dist/css/bootstrap.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="../../jumbotron.css" rel="stylesheet">
  </head>

  <body>

    <nav class="navbar navbar-inverse navbar-fixed-top">
    </nav>

    <!-- Main jumbotron for a primary marketing message or call to action -->
    <div class="jumbotron">
      <div class="container"  style="font-size:16px">
        <h2>YSC4216 Machine Learning</h2>
        <p> Yale-NUS College
	</p>

      </div>
    </div>


    <div class="container" style="font-size:16px">
      
      
	<center>
      <p class="bg-info">
	<br>
      </p>
	</center>
      <br>

      <h3>Description:</h3>
      <p>
      The goal of machine learning is to enable machines  to  identify 
      patterns from data, extract the patterns, and based on
      them, make
      a prediction automatically. These capabilities are the core of
      artificial intelligence (namely, to make machines learn
      without being explicitly programmed using fixed predetermined rules). 
      The applications of machine learning are immense, since
      nowadays we are bombarded with a huge number of
      various data from various sources. We hope machine learning can make
      sense of this huge seemingly incomprehensible  data.
      </p>
      <br>
      <b>Prerequisites</b>: Programming skill in Python (YSC2221), probability (YSC2243),
      statistical inference (YSC3249), calculus (YSC1216) and linear
      algebra (YSC2232). Contact the instructor for the possibility of
      waiving some prerequisites, along with your reasons.
      <br>
      <b>Textbook</b>: <a href="http://www.amazon.com/Pattern-Recognition-Learning-Information-Statistics/dp/0387310738/ref=sr_1_1?ie=UTF8&qid=1461689550&sr=8-1&keywords=pattern+recognition+and+machine+learning"
      target="_blank">"Pattern Recognition and Machine Learning"</a>,
      by Christopher Bishop. 

      <br>
      <b>Instructor</b>: <a href="http://tanrobby.github.io">Robby
	T. Tan</a> (robby.tan [att] yale-nus.edu.sg)

      <br>
      <br>
      <hr>
      <h3 id="schedule">Schedule:</h3>
<p>
The following schedule will not be strictly followed.
</p>

<br>
      
<table width="100%" 
       border = "0"
       class="table table-striped">
  <thead class="thead-inverse">
    
    <tr>
      <th width="12%"> Date
      <th> <center> Topic </center>
      <th width="20%"> <center> Lecture Note </center>
  </thead>
  <tbody>
    
    
    <!------------------------------------------------------------------------------>	  
    
    
    <tr>
      <td rowspan="1"> August 13
      <td>
	
	<b>1. INTRODUCTION</b>
	<br>
	<br>
	Additional resources (optional):
	<ul>
	  <li> Introduction to Machine Learning:
	  <a href="http://www.cs.princeton.edu/courses/archive/spr08/cos511/scribe_notes/0204.pdf"
	  target="_blank">pdf</a> | <a href="https://www.youtube.com/watch?v=cKxRvEZd3Mw" target="_blank">youtube</a>
	</ul>
	<br>
      <td align="left">
	<a href="https://www.dropbox.com/s/5xia98g13cwtpy8/YSC4216_lecture01.pdf?dl=0" target="_blank">Lecture Note 1</a>
    </tr>
     <!------------------------------------------------------------------------------>
    
    
    <tr>
      <td rowspan="1"> August 17
      <td>
	<b> 2. LEAST SQUARES REGRESSION (Part 1/2)</b>
	<br>
	<br>
	Reading:
	<ul>
	  <li> Chapter 1 (Introduction): Sect. 1.1 (Polynomial Curve
	    Fitting)		    
	</ul>
	<td>
    </tr>
	    
    <!------------------------------------------------------------------------------>
    
    <tr>
      <td rowspan="1"> August 20
      <td>
	<b> 3. LEAST SQUARES REGRESSION (Part 2/2)</b>
	<br>
	<br>
      <td align="left">
    </tr>
    
    <!------------------------------------------------------------------------------>
    
    <tr>
      <td rowspan="1"> August 24
      <td>
	<b>4. INTRODUCTION TO BAYESIAN INFERENCE</b>
	<br>
	<br>
      <td align="left">
    </tr>

    <!------------------------------------------------------------------------------>
    
	
    <tr>
      <td rowspan="1"> August 27
      <td>
	<b>5. MLE FOR REGRESSION</b>
	<br>
	<br>
      <td align="left">
    </tr>

    
    <!------------------------------------------------------------------------------>
    
    <tr>
      <td rowspan="1"> September 31
      <td>
	<b>6. MAP FOR REGRESSION</b>
	<br>
	<br>
      <td align="left">
    </tr>
    
    <!------------------------------------------------------------------------------>
    
    
    <tr>
      <td rowspan="1"> September 3
      <td>
	<b>7. BASIS FUNCTIONS</b>
	<br>
	<br>
      <td align="left">
    </tr>
    
    <!------------------------------------------------------------------------------>
    
    
    <tr>
      <td rowspan="1"> September 7
      <td>
	<b>8. GAUSSIAN DISTRIBUTIONS: COVARIANCE MATRIX</b>
	<br>
	<br>
      <td align="left">
    </tr>

    <!------------------------------------------------------------------------------>
	
   <tr>
     <td rowspan="1"> September 10
     <td> 
	<b>9. FULL BAYESIAN REGRESSION</b>
       <br>
       <br>
     <td align="left">
   </tr>
    <!------------------------------------------------------------------------------>
    
    
    <tr>
      <td rowspan="1"> September 14
      <td>
       <b>10. SEQUENTIAL LEARNING AND PREDICTIVE DISTRIBUTION</b> 
	<br>
	<br>
      <td align="left">
    </tr>	
    <!------------------------------------------------------------------------------>

    
    <tr>
      <td rowspan="1">  September 17
      <td>
	<b> 11. GAUSSIAN PROCESSES 1/2</b>
	<br>
	<br>
      <td align="left">
    </tr>
    <!------------------------------------------------------------------------------>

    <tr class="success">
      
      <td rowspan="1"> 
      <td>
	<b> RECESS WEEK </b>
	<br>
	<br>		
      <td>
    </tr>

    
    <!------------------------------------------------------------------------------>

    
    <tr>
      <td rowspan="1">  September 28
      <td>
	<b>12.  GAUSSIAN PROCESSES 2/2</b> 
	<br>
	<br>
      <td align="left">
    </tr>
    
    
    <!------------------------------------------------------------------------------>

    <tr>
      
      <td rowspan="1"> October 1
      <td>
	<b>13. LEAST-SQUARES CLASSIFICATION (Part 1/2)</b>
	<br>
	<br>
      <td align="left">
    </tr>


    <!------------------------------------------------------------------------------>


	
    <tr>
      <td rowspan="1"> October 5
      <td>
	<b>14. LEAST-SQUARES FOR CLASSIFICATION (Part 2/2)</b>
	<br>
	<br>
      <td align="left">
    </tr>
    
    <!------------------------------------------------------------------------------>

	
    <tr>
      <td rowspan="1"> October 8
      <td>
	<b>15. MLE FOR CLASSIFICATION</b>
	<br>
	<br>
      <td align="left">
    </tr>

    <!------------------------------------------------------------------------------>

    
    <tr>
      <td rowspan="1"> October 12
      <td>
 	<b>16. MAP FOR CLASSIFICATION</b>
	<br>
	<br>
      <td align="left">
    </tr>
    
    <!------------------------------------------------------------------------------>

    
	
    <tr>
      <td rowspan="1"> October 15
      <td>
	<b>17. FULL BAYESIAN FOR CLASSIFICATION</b>
	<br>
	<br>
      <td align="left">
    </tr>

    <!------------------------------------------------------------------------------>
    
    
    
    <tr>
      <td rowspan="1"> October 19
      <td>
	<b>18. PREDICTIVE DISTRIBUTION FOR CLASSIFICATION</b>
	<br>
	<br>
      <td align="left">

    <!------------------------------------------------------------------------------>

    
    
    <tr>
      <td rowspan="1"> October 22
      <td>
	<b>19. GAUSSIAN PROCESSES FOR CLASSIFICATION</b>
	<br>
	<br>
      <td align="left">
    </tr>

    <!------------------------------------------------------------------------------>

        <tr>
      <td rowspan="1"> October 26
      <td>
	  <b>20. PROBABILISTIC GENERATIVE MODELS</b>
	  <br>
	  <br>
      <td align="left">
    </tr>

    <!------------------------------------------------------------------------------>

    
    
    <tr>
      <td rowspan="1"> October 29
      <td>
	<b>21. SVM </b>
	<br>
	<br>
      <td align="left">
    </tr>

    
    <!------------------------------------------------------------------------------>
    
    
    
    <tr>
      <td rowspan="1"> November 2
      <td>
	<b>22. SVM (Part 2)</b>
	  <br>
	  <br>
      <td align="left">
    </tr>

    <!------------------------------------------------------------------------------>

	
    <tr>
	<td rowspan="1"> November 5
	<td>
	  <b>23. MIXTURE MODELS </b>
	  <br>
	  <br>
	<td align="left">
    </tr>

    <!------------------------------------------------------------------------------>
	  
    
    <tr>
      <td rowspan="1"> November 9
      <td>
	<b>24. THE EM ALGORITHM</b>
	<br>
	<br>
      <td align="left">
    </tr>
    
    <!------------------------------------------------------------------------------>
    
    
    <tr>
      <td rowspan="1"> November 12
      <td>
	<b>25. REVIEW</b>
      <td align="left">
    </tr>
    
    <!------------------------------------------------------------------------------>

    
    <!------------------------------------------------------------------------------>
    

    <tr class="danger">
      <td rowspan="1">
      <td>
	<b>FINAL EXAM</b>
	<br>
	<br>
	<td align="left"> 
    </tr>


    
  </tbody>
</table>
<br>
      


<!------------------------------------------------------------------------------>
<!------------------------------------------------------------------------------>
<!------------------------------------------------------------------------------>
<!------------------------------------------------------------------------------>

<br>
<br>
<br>
<hr>
<br>
<br>
<br>

      

</div>      
    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
    <script src="bootstrap-3.3.6-dist/js/bootstrap.min.js"></script>
  </body>
  <script type="text/javascript">
    var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
    document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
  </script>
<script type="text/javascript">
  try {
  var pageTracker = _gat._getTracker("UA-13131132-3");
  pageTracker._trackPageview();
  } catch(err) {}</script>
</html>
